# Global Tech Intelligence Node (DaaS Edition) ğŸ’

A "Stateless" Market Intelligence Dashboard that scrapes Hacker News "Who is Hiring" threads, extracts structured job data using **Groq Cloud (Llama 3.1 8B)**, and visualizes trends via a **Streamlit** web app.

**Business Model:** Data-as-a-Service (DaaS). The dashboard serves as a "Teaser" (Top 50 rows) to convert users to a paid CSV subscription.

## ğŸš€ Key Features
*   **Auto-Scraper:** Fetches latest HN threads automatically.
*   **AI Enrichment:** Llama 3.1 extracts `Job Role`, `Experience`, `Industry`, `Tech Stack`, and `Salary`.
*   **Zero Cost:** Runs entirely on free tiers (Groq API, GitHub Actions, Streamlit Community Cloud).
*   **Monetization Ready:** Dashboard restricts data access and links to Gumroad.

## ğŸ“‚ Repository Structure
```
â”œâ”€â”€ .github/workflows/  # Daily Scraping Automation (8 AM UTC)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/      # enriched jobs.csv (The Asset)
â”‚   â””â”€â”€ raw/            # Raw JSON from HN
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper.py      # HN API Fetcher
â”‚   â”œâ”€â”€ analyzer.py     # Groq/Llama 3 Processor
â”‚   â””â”€â”€ dashboard.py    # Streamlit UI (The Billboard)
â””â”€â”€ requirements.txt    # Python dependencies
```

## ğŸ› ï¸ Setup & Run
### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Secrets
Create a `.env` file:
```bash
GROQ_API_KEY=your_groq_api_key_here
```

### 3. Run Pipeline (Scrape + Analyze)
```bash
python src/run_pipeline.py
```

### 4. Launch Dashboard
```bash
streamlit run src/dashboard.py
```

## ğŸ¤– Automation (GitHub Actions)
This repo includes a workflow `.github/workflows/daily_scrape.yml` that runs daily.
**Requirement:** Add `GROQ_API_KEY` to your GitHub Repository Secrets.

## ğŸ“„ License
MIT
